{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from anytree import Node, RenderTree, Resolver, AnyNode, LevelOrderIter, PreOrderIter\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commandes pour générer les fichiers `.csv` depuis le dump envoyé par la DB :\n",
    "```\n",
    "ls | xargs -i basename {} .xlsx | xargs -i ssconvert {}.xlsx {}.csv\n",
    "find -name '*.csv' | xargs -i wc -l {}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILEPATH = '/home/alexis/mva/word_embeddings/wiki.fr.vec'\n",
    "\n",
    "PLF_NOMENCLATURES_FOLDER = './raw_data/'\n",
    "PLF_GRAPH_OUTPUT_FOLDER = '../server/resources/plf_all_nodes/'\n",
    "VOTES_OUTPUT_FOLDER = '../server/resources/plf_votes/'\n",
    "MAPPINGS_OUTPUT_FOLDER = '../server/resources/plf_mappings/'\n",
    "\n",
    "WORD_EMBEDDING_SIZE = 300\n",
    "K = 5\n",
    "MIN_YEAR = 2012\n",
    "MAX_YEAR = 2019\n",
    "ATTRIBUTES = ['tm', 'ms', 'pg', 'a', 'sa']\n",
    "ATTRIBUTE_ID = ['id_tms', 'id_ms', 'id_pg', 'id_a', 'id_sa']\n",
    "ROOT_NAME = 'root'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FastText pretrained embeddings. These should be downloaded from `https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.vec`.\n",
    "\n",
    "`EMBEDDING_FILE_PATH` should point to where this file is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "pretrained_embeddings = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDING_FILEPATH, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in `SOURCE_PLF_FILEPATH` and `TARGET_PLF_FILEPATH` contains all leaves of the PLF trees.\n",
    "\n",
    "This part of the code is used to build an explicit list of all nodes of these trees (not only leaves). It also builds node's embeddings the following way: each node's embedding is the concatenation of it's parent's _node-embedding_ and it's label's _word-embedding_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "    \"\"\"Parser for rows of input CSV files\"\"\"\n",
    "\n",
    "    def __init__(self, row):\n",
    "        self.id_tms = row[1]\n",
    "        self.tm = row[2]\n",
    "        self.id_ms = row[3]\n",
    "        self.ms = row[4]\n",
    "        self.id_pg = row[5]\n",
    "        self.pg = row[6]\n",
    "        self.id_a = row[7]\n",
    "        self.a = row[8]\n",
    "        # Parse sous-action if exists\n",
    "        self.id_sa = row[9]\n",
    "        self.sa = row[10]\n",
    "#         self.id_sa = row[9] if len(row[9]) > 0 else ''\n",
    "#         self.sa = row[10] if len(row[10]) > 0 else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_nodes_from_leaves(file_path, tree, resolver):\n",
    "    \"\"\"Iterates over input CSV file's lines\n",
    "    to build tree representing data.\n",
    "\n",
    "    Inputs:\n",
    "        - path to csv file under study\n",
    "        - anytree which will be updated\n",
    "        - anytree resolver for searching in given tree\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path, 'r') as input_file:\n",
    "        reader = csv.reader(input_file, delimiter=',', quotechar='\"')\n",
    "\n",
    "        # Skip header\n",
    "        next(reader, None)\n",
    "\n",
    "        # Iterate through rows\n",
    "        for row in reader:\n",
    "            # Parse current row\n",
    "            line = Line(row)\n",
    "\n",
    "            # Walk in the current tree and potentially\n",
    "            # build path of the leaf under study.\n",
    "            current_tree = tree\n",
    "            current_path = []\n",
    "            current_id = []\n",
    "\n",
    "            # Iterate through line attributes, which represent\n",
    "            # recursive nodes of the leaf under study.\n",
    "            for attribute, attribute_id in zip(ATTRIBUTES, ATTRIBUTE_ID):\n",
    "                # Get current node name\n",
    "                name = getattr(line, attribute)\n",
    "                if name == '':\n",
    "                    continue\n",
    "\n",
    "                # Update id array\n",
    "                if getattr(line, attribute_id):\n",
    "                    current_id.append(getattr(line, attribute_id))\n",
    "\n",
    "                # Update location in tree\n",
    "                current_path.append(name)\n",
    "                try:\n",
    "                    # If current node already exists,\n",
    "                    # simply update current_node with it\n",
    "                    current_tree = resolver.get(current_tree, str(hash(tuple(current_id))))\n",
    "                except:\n",
    "                    # If not, create a new node.\n",
    "\n",
    "                    # Compute embedding for current node\n",
    "\n",
    "                    ## Split current node's name\n",
    "                    words = keras.preprocessing.text.text_to_word_sequence(\n",
    "                        name,\n",
    "                        filters=\"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'´’™©®«»\",\n",
    "                        lower=True,\n",
    "                        split=' '\n",
    "                    )\n",
    "\n",
    "                    ## Initiate sentence embedding;\n",
    "                    ## Sentence embedding will be the average\n",
    "                    ## of all present word embeddings.\n",
    "                    sentence_embedding = np.zeros((1, WORD_EMBEDDING_SIZE))\n",
    "\n",
    "                    ## Create embedding for each word\n",
    "                    for word in words:\n",
    "                        try:\n",
    "                            sentence_embedding += pretrained_embeddings[word.lower()]\n",
    "                        except:\n",
    "                            # If word does not exist in pretrained embedding,\n",
    "                            # give it null embedding\n",
    "                            pass\n",
    "\n",
    "                    ## Normalize sentence embedding\n",
    "                    sentence_embedding /= max(len(words), 1)\n",
    "\n",
    "                    ## Concatenate embedding with parent node embedding\n",
    "                    node_embedding = np.concatenate((\n",
    "                        np.array(current_tree.embedding[0]).reshape((1, WORD_EMBEDDING_SIZE)) +\n",
    "                        np.array(current_tree.embedding[1]).reshape((1, WORD_EMBEDDING_SIZE)),\n",
    "                        sentence_embedding\n",
    "                    ))\n",
    "                    \n",
    "                    # Update node\n",
    "                    current_tree = AnyNode(\n",
    "                        parent=current_tree,\n",
    "                        name=current_path[-1],\n",
    "                        embedding=node_embedding,\n",
    "                        current_path=current_path.copy(),\n",
    "                        id=current_id.copy(),\n",
    "                        hashed_id=str(hash(tuple(current_id))),\n",
    "                        data=line\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver = Resolver('hashed_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test previous functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PLF_FILEPATH = '../server/resources/plf_leaves_only/plf2016.csv'\n",
    "TARGET_PLF_FILEPATH = '../server/resources/plf_leaves_only/plf2017.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 63.9 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "source_tree = AnyNode(name=ROOT_NAME, parent=None, embedding=np.zeros((2, WORD_EMBEDDING_SIZE)), id=[], hashed_id=str(hash(tuple())))\n",
    "build_all_nodes_from_leaves(SOURCE_PLF_FILEPATH, source_tree, resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 35.9 ms, total: 16.4 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_tree = AnyNode(name=ROOT_NAME, parent=None, embedding=np.zeros((2, WORD_EMBEDDING_SIZE)), id=[], hashed_id=str(hash(tuple())))\n",
    "build_all_nodes_from_leaves(TARGET_PLF_FILEPATH, target_tree, resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check embedding shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that all created embeddings have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ok\n"
     ]
    }
   ],
   "source": [
    "for node in LevelOrderIter(source_tree):\n",
    "    assert(node.embedding.shape == (2, WORD_EMBEDDING_SIZE))\n",
    "print('Test ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nearest_neighbours(tree, k=2):\n",
    "    \"\"\"Build and return scikit NearestNeighbors.\n",
    "    \n",
    "    Inputs:\n",
    "        - anytree\n",
    "        - number of nearest neighbours\n",
    "    \"\"\"\n",
    "\n",
    "    # Stack and flatten all embeddings\n",
    "    # from a given tree\n",
    "    embeddings = np.array([node.embedding.flatten() for node in LevelOrderIter(tree) if node.name != ROOT_NAME])\n",
    "    indices = [node.id for node in LevelOrderIter(tree) if node.name != ROOT_NAME]\n",
    "\n",
    "    # Initiate scikit learn NearestNeighbors\n",
    "    neighbours = NearestNeighbors(\n",
    "        n_neighbors=k,\n",
    "        algorithm='ball_tree'\n",
    "    ).fit(embeddings)\n",
    "\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tree_to_neighbours(tree, neighbours):\n",
    "    embeddings = np.array([node.embedding.flatten() for node in LevelOrderIter(tree) if node.name != ROOT_NAME])\n",
    "\n",
    "    print('Computing KNN...')\n",
    "    distances, indices = neighbours.kneighbors(embeddings)\n",
    "\n",
    "    return distances, indices, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_name(node):\n",
    "    if node.parent:\n",
    "        return (get_path_name(node.parent) if node.parent else []) + [node.name]\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_csv_file(tree, filename):\n",
    "    '''Outputs all nodes of a given tree in a CSV file.'''\n",
    "\n",
    "    with open(os.path.join(PLF_GRAPH_OUTPUT_FOLDER, filename), 'w+') as f:\n",
    "        f.write('Node index;Type mission;Code type mission;Mission;Code mission;Programme;Code programme;Action;Code action;Sous-action;Code sous-action\\n')\n",
    "\n",
    "        for child_index, child in enumerate(LevelOrderIter(tree)):\n",
    "            if child.name != ROOT_NAME:\n",
    "                # Substract 1 to current child_index becose\n",
    "                # root node is dismissed\n",
    "                f.write('{};'.format(str(child_index-1)))\n",
    "                path_name = get_path_name(child)\n",
    "\n",
    "                for i, attribute in enumerate(ATTRIBUTES):\n",
    "                    if i < len(path_name):\n",
    "                        f.write('{};{};'.format(\n",
    "                            path_name[i],\n",
    "                            child.id[i]\n",
    "                        ))\n",
    "                    else:\n",
    "                        f.write(';;')\n",
    "                f.write('\\b\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Suggestion:\n",
    "    def __init__(self):\n",
    "        self.distance = None\n",
    "        self.upvotes = 0\n",
    "        self.downvotes = 0\n",
    "        self.commentaires = []\n",
    "\n",
    "class Mapping:\n",
    "    def __init__(self):\n",
    "        self.distance = None\n",
    "\n",
    "def neighbours_to_files(from_tree, to_tree, indices, distances, filename, jsonOnly=False):\n",
    "    mappingsDict = defaultdict(list)\n",
    "    votesDict = defaultdict(lambda: defaultdict(Suggestion))\n",
    "    \n",
    "    from_tree_node_list = [node for node in LevelOrderIter(from_tree) if node.name != ROOT_NAME]\n",
    "    to_tree_node_list = [node for node in LevelOrderIter(to_tree) if node.name != ROOT_NAME]\n",
    "\n",
    "    for source_index, (row_indices, row_distances) in enumerate(zip(indices, distances)):\n",
    "        # Fill mappingsDict\n",
    "        mappingsDict['-'.join(from_tree_node_list[source_index].id)].append(dict({\n",
    "            'distance': row_distances[0],\n",
    "            'libelles': to_tree_node_list[row_indices[0]].current_path,\n",
    "            'codes': to_tree_node_list[row_indices[0]].id\n",
    "        }))\n",
    "\n",
    "        # Fill votesDict\n",
    "        for target_index, target_distance in zip(row_indices, row_distances):\n",
    "            votesDict[str(source_index)][str(target_index)].distance = target_distance\n",
    "\n",
    "    with open(os.path.join(MAPPINGS_OUTPUT_FOLDER, '{}.json'.format(filename)), 'w+') as f:\n",
    "        json.dump(mappingsDict, f, default=lambda o: o.__dict__)\n",
    "\n",
    "    if not jsonOnly:\n",
    "        with open(os.path.join(MAPPINGS_OUTPUT_FOLDER, '{}.csv'.format(filename)), 'w+') as f:\n",
    "            for source_id in mappingsDict:\n",
    "                for target_id in mappingsDict[source_id]:\n",
    "                    f.write('{};{};{}\\n'.format(source_id, target_id, mappingsDict[source_id][0]['distance']))\n",
    "\n",
    "    with open(os.path.join(VOTES_OUTPUT_FOLDER, '{}.json'.format(filename)), 'w+') as f:\n",
    "        json.dump(votesDict, f, default=lambda o: o.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_trees(from_tree, to_tree, output_filename_without_extension=None):\n",
    "    to_neighbours = build_nearest_neighbours(to_tree, k=K)\n",
    "    distances, indices, embeddings = fit_tree_to_neighbours(from_tree, to_neighbours)\n",
    "\n",
    "    if output_filename_without_extension:\n",
    "        neighbours_to_files(from_tree, to_tree, indices, distances, output_filename_without_extension, jsonOnly=True)\n",
    "\n",
    "    return distances, indices, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test previous functions\n",
    "Execute previous functions on loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_to_csv_file(source_tree, os.path.basename(SOURCE_PLF_FILEPATH))\n",
    "tree_to_csv_file(target_tree, os.path.basename(TARGET_PLF_FILEPATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute pairs both ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KNN...\n",
      "CPU times: user 7.51 s, sys: 19.9 ms, total: 7.53 s\n",
      "Wall time: 7.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distances, indices, embeddings = map_trees(source_tree, target_tree, output_filename_without_extension='{}_to_{}'.format(\n",
    "    os.path.splitext(os.path.basename(SOURCE_PLF_FILEPATH))[0],\n",
    "    os.path.splitext(os.path.basename(TARGET_PLF_FILEPATH))[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing KNN...\n",
      "CPU times: user 7.64 s, sys: 35.9 ms, total: 7.67 s\n",
      "Wall time: 7.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "distances, indices, embeddings = map_trees(source_tree, target_tree, output_filename_without_extension='{}_to_{}'.format(\n",
    "    os.path.splitext(os.path.basename(TARGET_PLF_FILEPATH))[0],\n",
    "    os.path.splitext(os.path.basename(SOURCE_PLF_FILEPATH))[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build all mappings & mapping suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mapping(source_year):\n",
    "    SOURCE_PLF_FILEPATH = os.path.join(PLF_NOMENCLATURES_FOLDER, 'plf_{}.csv'.format(source_year))\n",
    "    TARGET_PLF_FILEPATH = os.path.join(PLF_NOMENCLATURES_FOLDER, 'plf_{}.csv'.format(source_year+1))\n",
    "\n",
    "    print('1. Compute embeddings...')\n",
    "    source_tree = AnyNode(name=ROOT_NAME, parent=None, embedding=np.zeros((2, WORD_EMBEDDING_SIZE)), id=[], hashed_id=str(hash(tuple())))\n",
    "    build_all_nodes_from_leaves(SOURCE_PLF_FILEPATH, source_tree, resolver)\n",
    "    target_tree = AnyNode(name=ROOT_NAME, parent=None, embedding=np.zeros((2, WORD_EMBEDDING_SIZE)), id=[], hashed_id=str(hash(tuple())))\n",
    "    build_all_nodes_from_leaves(TARGET_PLF_FILEPATH, target_tree, resolver)\n",
    "    \n",
    "    tree_to_csv_file(source_tree, os.path.basename(SOURCE_PLF_FILEPATH))\n",
    "    tree_to_csv_file(target_tree, os.path.basename(TARGET_PLF_FILEPATH))\n",
    "\n",
    "    print('2. Compute mapping and mapping suggestions (also called votes)...')\n",
    "    distances, indices, embeddings = map_trees(source_tree, target_tree, output_filename_without_extension='{}_to_{}'.format(\n",
    "        os.path.splitext(os.path.basename(SOURCE_PLF_FILEPATH))[0],\n",
    "        os.path.splitext(os.path.basename(TARGET_PLF_FILEPATH))[0]\n",
    "    ))\n",
    "    # Uncomment/comment the following lines if you want mappings and suggestions to be computed both ways (n -> n+1 and n+1 -> n)\n",
    "    distances, indices, embeddings = map_trees(source_tree, target_tree, output_filename_without_extension='{}_to_{}'.format(\n",
    "        os.path.splitext(os.path.basename(TARGET_PLF_FILEPATH))[0],\n",
    "        os.path.splitext(os.path.basename(SOURCE_PLF_FILEPATH))[0]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building comparison for years 2012-2013\n",
      "1. Compute embeddings...\n",
      "2. Compute mapping and mapping suggestions (also called votes)...\n",
      "Computing KNN...\n",
      "Computing KNN...\n",
      "\n",
      "\n",
      "Building comparison for years 2013-2014\n",
      "1. Compute embeddings...\n",
      "2. Compute mapping and mapping suggestions (also called votes)...\n",
      "Computing KNN...\n",
      "Computing KNN...\n",
      "\n",
      "\n",
      "Building comparison for years 2014-2015\n",
      "1. Compute embeddings...\n",
      "2. Compute mapping and mapping suggestions (also called votes)...\n",
      "Computing KNN...\n",
      "Computing KNN...\n",
      "\n",
      "\n",
      "Building comparison for years 2015-2016\n",
      "1. Compute embeddings...\n",
      "2. Compute mapping and mapping suggestions (also called votes)...\n",
      "Computing KNN...\n",
      "Computing KNN...\n",
      "\n",
      "\n",
      "Building comparison for years 2016-2017\n",
      "1. Compute embeddings...\n",
      "2. Compute mapping and mapping suggestions (also called votes)...\n",
      "Computing KNN...\n",
      "Computing KNN...\n",
      "\n",
      "\n",
      "Building comparison for years 2017-2018\n",
      "1. Compute embeddings...\n",
      "2. Compute mapping and mapping suggestions (also called votes)...\n",
      "Computing KNN...\n",
      "Computing KNN...\n",
      "\n",
      "\n",
      "Building comparison for years 2018-2019\n",
      "1. Compute embeddings...\n"
     ]
    }
   ],
   "source": [
    "for year in range(MIN_YEAR, MAX_YEAR):\n",
    "    print('Building comparison for years {}-{}'.format(year, year+1))\n",
    "    build_mapping(year)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few metrics about the generated pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of not directly matched: 10.02 % (249 / 2484)\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of not directly matched: {:.2f} % ({} / {})'.format(\n",
    "        distances[distances[:,0] != 0].shape[0] / distances.shape[0] * 100,\n",
    "        distances[distances[:,0] != 0].shape[0],\n",
    "        distances.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of not uniquely matched: 0.24 % (6 / 2484)\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of not uniquely matched: {:.2f} % ({} / {})'.format(\n",
    "        len([1 for d in distances if (d[0] == 0 and d[1] == 0)]) / distances.shape[0] * 100,\n",
    "        len([1 for d in distances if (d[0] == 0 and d[1] == 0)]),\n",
    "        distances.shape[0]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee69b76080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10, 4))\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.set_title('Distribution of distances of imperfectly matched nodes')\n",
    "n, bins, patches = ax.hist(distances[distances[:,0] != 0][:,0], 50)\n",
    "# n, bins, patches = ax.hist(distances[:,1], 50, alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
